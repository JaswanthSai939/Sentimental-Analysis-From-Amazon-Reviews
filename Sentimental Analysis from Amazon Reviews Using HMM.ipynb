{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the 'punkt_tab' resource using NLTK Downloader\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "OUdPnh7u8CdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a737fb-5501-40d8-f99a-a11d4409af28"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pickle\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/reviews_Grocery_and_Gourmet_Food_5.csv')\n",
        "data = data[['reviewText', 'overall']].dropna()\n",
        "\n",
        "# Define mapping for labels\n",
        "rating_to_label = {\n",
        "    1: 'negative',\n",
        "    2: 'negative',\n",
        "    3: 'neutral',\n",
        "    4: 'positive',\n",
        "    5: 'positive'\n",
        "}\n",
        "data['label'] = data['overall'].map(rating_to_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-H5igQw8FLc",
        "outputId": "68e425dd-fedd-4df8-b423-f36e15b7c410"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated preprocessing function\n",
        "def preprocess_text_advanced(text):\n",
        "    # Step 1: Handle negations\n",
        "    text = handle_negations_scope(text)\n",
        "\n",
        "    # Step 2: Tokenize, remove stopwords, and lemmatize\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords, keep tokens with underscores\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "# Test the preprocessing again\n",
        "user_input = \"The product is not good and not worth the price.\"\n",
        "processed_text = handle_negations_scope(user_input)\n",
        "processed_tokens = preprocess_text_advanced(processed_text)\n",
        "print(f\"Processed Text after Negation Handling: {processed_text}\")\n",
        "print(f\"Processed Tokens: {processed_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BjyJtPi8M4_",
        "outputId": "a006b8c7-0a44-463c-f588-15999f59ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text after Negation Handling: the product is not_good and not_worth the price .\n",
            "Processed Tokens: ['product', 'not_good', 'not_worth', 'price', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess dataset\n",
        "train_data['tokens'] = train_data['reviewText'].apply(preprocess_text_advanced)\n",
        "test_data['tokens'] = test_data['reviewText'].apply(preprocess_text_advanced)\n",
        "\n",
        "# Create vocabulary and word-to-index mapping\n",
        "all_tokens = [token for tokens in train_data['tokens'] for token in tokens]\n",
        "vocab = list(set(all_tokens))\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Add OOV token\n",
        "word_to_index[\"<OOV>\"] = len(word_to_index)\n",
        "n_observations = len(word_to_index)"
      ],
      "metadata": {
        "id": "s3oUn8o-8Q94"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define state mapping\n",
        "state_mapping = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
        "n_states = len(state_mapping)\n",
        "\n",
        "# Encode tokens and states\n",
        "def encode_tokens(tokens):\n",
        "    return [word_to_index.get(token, word_to_index[\"<OOV>\"]) for token in tokens]\n",
        "\n",
        "encoded_train_sequences = [encode_tokens(tokens) for tokens in train_data['tokens']]\n",
        "encoded_state_sequences = [[state_mapping[label]] for label in train_data['label']]\n",
        "\n",
        "# Bigram HMM Implementation\n",
        "class BigramHMM:\n",
        "    def __init__(self, n_states, n_observations):\n",
        "        self.n_states = n_states\n",
        "        self.n_observations = n_observations\n",
        "        self.transition_probs = np.full((n_states, n_states), 1.0 / n_states)  # Bigram transitions\n",
        "        self.emission_probs = np.full((n_states, n_observations), 1.0 / n_observations)\n",
        "        self.start_probs = np.full(n_states, 1.0 / n_states)\n",
        "\n",
        "    def train(self, sequences, state_sequences, alpha=1.0):\n",
        "        # Update start probabilities\n",
        "        for state_seq in state_sequences:\n",
        "            self.start_probs[state_seq[0]] += 1\n",
        "        self.start_probs += alpha\n",
        "        self.start_probs /= self.start_probs.sum()\n",
        "\n",
        "        # Update bigram transition probabilities\n",
        "        for state_seq in state_sequences:\n",
        "            for i in range(len(state_seq) - 1):\n",
        "                self.transition_probs[state_seq[i], state_seq[i + 1]] += 1\n",
        "        self.transition_probs += alpha\n",
        "        self.transition_probs /= self.transition_probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "        # Update emission probabilities\n",
        "        for seq, state_seq in zip(sequences, state_sequences):\n",
        "            for obs, state in zip(seq, state_seq):\n",
        "                self.emission_probs[state, obs] += 1\n",
        "        self.emission_probs += alpha\n",
        "        self.emission_probs /= self.emission_probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def viterbi(self, sequence):\n",
        "        T = len(sequence)\n",
        "        viterbi_probs = np.zeros((self.n_states, T))\n",
        "        backpointer = np.zeros((self.n_states, T), dtype=int)\n",
        "\n",
        "        # Initialize base case\n",
        "        for s in range(self.n_states):\n",
        "            viterbi_probs[s, 0] = self.start_probs[s] * self.emission_probs[s, sequence[0]]\n",
        "            backpointer[s, 0] = 0\n",
        "\n",
        "        # Dynamic programming\n",
        "        for t in range(1, T):\n",
        "            for s in range(self.n_states):\n",
        "                probabilities = viterbi_probs[:, t - 1] * self.transition_probs[:, s] * self.emission_probs[s, sequence[t]]\n",
        "                viterbi_probs[s, t] = np.max(probabilities)\n",
        "                backpointer[s, t] = np.argmax(probabilities)\n",
        "\n",
        "        # Backtrack to find the best path\n",
        "        best_path = np.zeros(T, dtype=int)\n",
        "        best_path[-1] = np.argmax(viterbi_probs[:, T - 1])\n",
        "        for t in range(T - 2, -1, -1):\n",
        "            best_path[t] = backpointer[best_path[t + 1], t + 1]\n",
        "\n",
        "        return best_path"
      ],
      "metadata": {
        "id": "U0nf--i98U0G"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Bigram HMM model\n",
        "bigram_hmm_model = BigramHMM(n_states=n_states, n_observations=n_observations)\n",
        "bigram_hmm_model.train(encoded_train_sequences, encoded_state_sequences, alpha=1.0)\n",
        "\n",
        "# Save the model to a file for later use\n",
        "with open('bigram_hmm_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump({'model': bigram_hmm_model, 'vocab': vocab, 'word_to_index': word_to_index, 'state_mapping': state_mapping}, model_file)\n",
        "\n",
        "print(\"Model training completed and saved successfully.\")"
      ],
      "metadata": {
        "id": "arrx1AtR8cF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf30125-0b36-471f-cba6-02c5197817c1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "encoded_test_sequences = [encode_tokens(tokens) for tokens in test_data['tokens']]\n",
        "true_labels = [state_mapping[label] for label in test_data['label']]\n",
        "predicted_labels = []\n",
        "\n",
        "for seq in encoded_test_sequences:\n",
        "    if len(seq) > 0:\n",
        "        predicted_state = bigram_hmm_model.viterbi(seq)[0]\n",
        "    else:\n",
        "        predicted_state = state_mapping['neutral']  # Default to 'neutral' if the sequence is empty\n",
        "    predicted_labels.append(predicted_state)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDnau9iW9_km",
        "outputId": "5834b085-8369-495f-9d9a-d1b3630629b2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80\n",
            "Precision: 0.70\n",
            "Recall: 0.80\n",
            "F1 Score: 0.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the negative class is adequately represented in the balanced training set\n",
        "negative_count = len(balanced_train_data[balanced_train_data['label'] == 'negative'])\n",
        "if negative_count < 0.3 * len(balanced_train_data):\n",
        "    # Augment negative reviews to increase representation\n",
        "    additional_negative_data = negative_data.sample(int(0.3 * len(balanced_train_data)) - negative_count, replace=True, random_state=42)\n",
        "    balanced_train_data = pd.concat([balanced_train_data, additional_negative_data])\n",
        "\n",
        "# Re-process tokens for the updated balanced dataset\n",
        "balanced_train_data['tokens'] = balanced_train_data['reviewText'].apply(preprocess_text_advanced)\n",
        "\n",
        "# Encode tokens and states for the updated balanced data\n",
        "encoded_train_sequences = [encode_tokens(tokens) for tokens in balanced_train_data['tokens']]\n",
        "encoded_state_sequences = [[state_mapping[label]] for label in balanced_train_data['label']]"
      ],
      "metadata": {
        "id": "AJAwL5BD-XaX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the Bigram HMM model with higher alpha for smoothing\n",
        "bigram_hmm_model = BigramHMM(n_states=n_states, n_observations=n_observations)\n",
        "bigram_hmm_model.train(encoded_train_sequences, encoded_state_sequences, alpha=10.0)  # Increase smoothing to 10\n",
        "\n",
        "# Save the retrained model\n",
        "with open('bigram_hmm_model_augmented.pkl', 'wb') as model_file:\n",
        "    pickle.dump({'model': bigram_hmm_model, 'vocab': vocab, 'word_to_index': word_to_index, 'state_mapping': state_mapping}, model_file)\n",
        "\n",
        "print(\"Retrained the model with augmented data and increased smoothing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmu-OMM3_LIe",
        "outputId": "d1cad8dd-36ed-4cc4-979d-39861721b2c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrained the model with augmented data and increased smoothing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment using the retrained model\n",
        "def predict_review_bigram_augmented(text):\n",
        "    # Load the saved balanced and augmented model\n",
        "    with open('bigram_hmm_model_augmented.pkl', 'rb') as model_file:\n",
        "        data = pickle.load(model_file)\n",
        "        bigram_hmm_model = data['model']\n",
        "        word_to_index = data['word_to_index']\n",
        "        state_mapping = data['state_mapping']\n",
        "\n",
        "    # Preprocess and encode the input text\n",
        "    preprocessed_text = handle_negations_scope(text)\n",
        "    tokens = preprocess_text_advanced(preprocessed_text)\n",
        "    encoded_sequence = [word_to_index.get(token, word_to_index[\"<OOV>\"]) for token in tokens]\n",
        "\n",
        "    # Predict the most likely state sequence\n",
        "    if len(encoded_sequence) == 0:\n",
        "        return \"Unknown (not enough information)\"\n",
        "\n",
        "    predicted_states = bigram_hmm_model.viterbi(encoded_sequence)\n",
        "    predicted_label = [k for k, v in state_mapping.items() if v == predicted_states[0]][0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Test multiple inputs again\n",
        "test_sentences = [\n",
        "    \"I am extremely happy with my purchase. Highly recommend it!\",\n",
        "    \"This is by far the best product I've used. Amazing value for money.\",\n",
        "    \"The customer service was fantastic, and the product works perfectly.\",\n",
        "    \"I love it! It does exactly what it says, and the performance is top-notch.\",\n",
        "\n",
        "    # Neutral Reviews\n",
        "    \"It's neither great nor bad. Just a regular product.\",\n",
        "    \"The quality is decent for the price, but I have used better alternatives.\",\n",
        "    \"The product works, but I wasn't particularly impressed or disappointed.\",\n",
        "    \"The packaging was good, and the delivery was on time, but the product is average.\",\n",
        "\n",
        "    # Negative Reviews\n",
        "    \"The product is not good and not worth the money.\",\n",
        "    \"I am not happy with the quality at all. Would not recommend.\",\n",
        "    \"The product broke after only a week of use. Very disappointing.\",\n",
        "    \"I expected much better quality. The product feels cheap and flimsy.\",\n",
        "    \"This was a waste of money. It doesn't work as advertised.\"\n",
        "\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    print(f\"Input: {sentence}\")\n",
        "    print(f\"Predicted Class: {predict_review_bigram_augmented(sentence)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj2f5bBT_Ofa",
        "outputId": "a43d6b48-3fc3-487f-c523-6c9b26f15eaa"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I am extremely happy with my purchase. Highly recommend it!\n",
            "Predicted Class: positive\n",
            "\n",
            "Input: This is by far the best product I've used. Amazing value for money.\n",
            "Predicted Class: positive\n",
            "\n",
            "Input: The customer service was fantastic, and the product works perfectly.\n",
            "Predicted Class: neutral\n",
            "\n",
            "Input: I love it! It does exactly what it says, and the performance is top-notch.\n",
            "Predicted Class: positive\n",
            "\n",
            "Input: It's neither great nor bad. Just a regular product.\n",
            "Predicted Class: neutral\n",
            "\n",
            "Input: The quality is decent for the price, but I have used better alternatives.\n",
            "Predicted Class: positive\n",
            "\n",
            "Input: The product works, but I wasn't particularly impressed or disappointed.\n",
            "Predicted Class: negative\n",
            "\n",
            "Input: The packaging was good, and the delivery was on time, but the product is average.\n",
            "Predicted Class: neutral\n",
            "\n",
            "Input: The product is not good and not worth the money.\n",
            "Predicted Class: negative\n",
            "\n",
            "Input: I am not happy with the quality at all. Would not recommend.\n",
            "Predicted Class: negative\n",
            "\n",
            "Input: The product broke after only a week of use. Very disappointing.\n",
            "Predicted Class: negative\n",
            "\n",
            "Input: I expected much better quality. The product feels cheap and flimsy.\n",
            "Predicted Class: negative\n",
            "\n",
            "Input: This was a waste of money. It doesn't work as advertised.\n",
            "Predicted Class: negative\n",
            "\n"
          ]
        }
      ]
    }
  ]
}